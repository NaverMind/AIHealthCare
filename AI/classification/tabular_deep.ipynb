{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOkxPU1FDu4H9eCABytxErm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["# # 세팅"],"metadata":{"id":"qhC1MGwTFu-O"}},{"cell_type":"code","source":["# https://github.com/jrzaurin/pytorch-widedeep/blob/master/pytorch_widedeep/\n","!pip install pytorch-widedeep"],"metadata":{"id":"xiL4DOoYglu9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670306894218,"user_tz":-540,"elapsed":13221,"user":{"displayName":"DK D","userId":"10687755219747411266"}},"outputId":"d89d45d7-d1d2-48e5-f683-018f705b9e01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-widedeep\n","  Downloading pytorch_widedeep-1.2.1-py3-none-any.whl (21.1 MB)\n","\u001b[K     |████████████████████████████████| 21.1 MB 1.1 MB/s \n","\u001b[?25hCollecting einops\n","  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n","\u001b[K     |████████████████████████████████| 41 kB 615 kB/s \n","\u001b[?25hCollecting fastparquet>=0.8.1\n","  Downloading fastparquet-2022.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 66.9 MB/s \n","\u001b[?25hRequirement already satisfied: imutils in /usr/local/lib/python3.8/dist-packages (from pytorch-widedeep) (0.5.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pytorch-widedeep) (4.64.1)\n","Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.8/dist-packages (from pytorch-widedeep) (1.3.5)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (from pytorch-widedeep) (3.4.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from pytorch-widedeep) (1.12.1+cu113)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.8/dist-packages (from pytorch-widedeep) (9.0.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from pytorch-widedeep) (1.14.1)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.8/dist-packages (from pytorch-widedeep) (1.21.6)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from pytorch-widedeep) (0.13.1+cu113)\n","Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.8/dist-packages (from pytorch-widedeep) (1.7.3)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (from pytorch-widedeep) (3.6.0)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.8/dist-packages (from pytorch-widedeep) (4.6.0.66)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-widedeep) (1.0.2)\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[K     |████████████████████████████████| 512 kB 89.9 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from fastparquet>=0.8.1->pytorch-widedeep) (2022.11.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from fastparquet>=0.8.1->pytorch-widedeep) (21.3)\n","Collecting cramjam>=2.3\n","  Downloading cramjam-2.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 62.5 MB/s \n","\u001b[?25hCollecting pandas>=1.3.5\n","  Downloading pandas-1.5.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n","\u001b[K     |████████████████████████████████| 12.2 MB 78.3 MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.5->pytorch-widedeep) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.5->pytorch-widedeep) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.5->pytorch-widedeep) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->pytorch-widedeep) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->pytorch-widedeep) (3.1.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim->pytorch-widedeep) (5.2.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->fastparquet>=0.8.1->pytorch-widedeep) (3.0.9)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (3.3.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (3.0.10)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (0.10.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (2.0.8)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (1.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (2.0.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (57.4.0)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (0.9.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (3.0.8)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (2.11.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (2.23.0)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (8.1.5)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (2.4.5)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (1.10.2)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (0.7.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy->pytorch-widedeep) (1.0.3)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy->pytorch-widedeep) (4.1.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytorch-widedeep) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytorch-widedeep) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytorch-widedeep) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytorch-widedeep) (2022.9.24)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->pytorch-widedeep) (0.0.3)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->pytorch-widedeep) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy->pytorch-widedeep) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy->pytorch-widedeep) (2.0.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->pytorch-widedeep) (7.1.2)\n","Installing collected packages: pandas, cramjam, torchmetrics, fastparquet, einops, pytorch-widedeep\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","Successfully installed cramjam-2.6.2 einops-0.6.0 fastparquet-2022.12.0 pandas-1.5.2 pytorch-widedeep-1.2.1 torchmetrics-0.11.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Gr6eRA5fJoC","executionInfo":{"status":"ok","timestamp":1670306920649,"user_tz":-540,"elapsed":26435,"user":{"displayName":"DK D","userId":"10687755219747411266"}},"outputId":"561232e5-f965-4fba-8410-dd18ba1b44c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["import os, random, torch\n","import numpy as np\n","import pandas as pd\n","def setSeeds(seed = 5):\n","    # 랜덤 시드를 설정하여 매 코드를 실행할 때마다 동일한 결과를 얻게 합니다.\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)    \n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","setSeeds()\n","from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing"]},{"cell_type":"code","source":["# string타입 : exercise, conditions\n","# frame, active는 train에 포함 X\n","exercise_list = ['플랭크', '푸시업', '니푸쉬업', '스탠딩 사이드 크런치' ,  '굿모닝',  'Y - Exercise',  '스탠딩 니업', '크런치', '바이시클 크런치' , '사이드 런지' ]\n","pts_list = ['pts.Nose.x', 'pts.Nose.y', 'pts.Nose.z',\n","       'pts.Left Eye.x', 'pts.Left Eye.y', 'pts.Left Eye.z', 'pts.Right Eye.x',\n","       'pts.Right Eye.y', 'pts.Right Eye.z', 'pts.Left Ear.x',\n","       'pts.Left Ear.y', 'pts.Left Ear.z', 'pts.Right Ear.x',\n","       'pts.Right Ear.y', 'pts.Right Ear.z', 'pts.Left Shoulder.x',\n","       'pts.Left Shoulder.y', 'pts.Left Shoulder.z', 'pts.Right Shoulder.x',\n","       'pts.Right Shoulder.y', 'pts.Right Shoulder.z', 'pts.Left Elbow.x',\n","       'pts.Left Elbow.y', 'pts.Left Elbow.z', 'pts.Right Elbow.x',\n","       'pts.Right Elbow.y', 'pts.Right Elbow.z', 'pts.Left Wrist.x',\n","       'pts.Left Wrist.y', 'pts.Left Wrist.z', 'pts.Right Wrist.x',\n","       'pts.Right Wrist.y', 'pts.Right Wrist.z', 'pts.Left Hip.x',\n","       'pts.Left Hip.y', 'pts.Left Hip.z', 'pts.Right Hip.x',\n","       'pts.Right Hip.y', 'pts.Right Hip.z', 'pts.Left Knee.x',\n","       'pts.Left Knee.y', 'pts.Left Knee.z', 'pts.Right Knee.x',\n","       'pts.Right Knee.y', 'pts.Right Knee.z', 'pts.Left Ankle.x',\n","       'pts.Left Ankle.y', 'pts.Left Ankle.z', 'pts.Right Ankle.x',\n","       'pts.Right Ankle.y', 'pts.Right Ankle.z', 'pts.Neck.x', 'pts.Neck.y',\n","       'pts.Neck.z', 'pts.Left Palm.x', 'pts.Left Palm.y', 'pts.Left Palm.z',\n","       'pts.Right Palm.x', 'pts.Right Palm.y', 'pts.Right Palm.z',\n","       'pts.Back.x', 'pts.Back.y', 'pts.Back.z', 'pts.Waist.x', 'pts.Waist.y',\n","       'pts.Waist.z', 'pts.Left Foot.x', 'pts.Left Foot.y', 'pts.Left Foot.z',\n","       'pts.Right Foot.x', 'pts.Right Foot.y', 'pts.Right Foot.z']\n","condition_list = [ 'condition0', 'condition1', 'condition2', 'condition3', 'condition4','exercise']\n","label_list = [  'value0', 'value1', 'value2', 'value3', 'value4']\n","angle_dict = {'spine' : ['pts.Neck', \"pts.Back\", \"pts.Waist\"], \n","              \"left_elbow\":[\"pts.Left Wrist\", \"pts.Left Elbow\", \"pts.Left Shoulder\"],\n","              \"right_elbow\":[\"pts.Right Wrist\", \"pts.Right Elbow\", \"pts.Right Shoulder\"],\n","              \"left_hand_position\" : [\"pts.Left Wrist\", 'pts.Left Shoulder', \"pts.Back\"],\n","              \"right_hand_position\" : [\"pts.Right Wrist\", 'pts.Right Shoulder', \"pts.Back\"],\n","              \"head\" : [\"pts.Nose\", 'pts.Neck', \"pts.Back\"],\n","              \"left_knee\" : [\"pts.Left Ankle\", 'pts.Left Knee', \"pts.Left Hip\"],\n","              \"right_knee\" : [\"pts.Right Ankle\", 'pts.Right Knee', \"pts.Right Hip\"],\n","              \"sight\" : [\"pts.Left Eye\", 'pts.Neck', \"pts.Left Shoulder\"],\n","              \"left_hand\" : [\"pts.Left Palm\", \"pts.Left Wrist\", \"pts.Left Elbow\"],\n","              \"right_hand\" : [\"pts.Right Palm\", \"pts.Right Wrist\", \"pts.Right Elbow\"],\n","              \"left_knee_elbow\" : [\"pts.Left Elbow\", \"pts.Waist\", \"pts.Left Knee\"],\n","              \"right_knee_elbow\" : [\"pts.Right Elbow\", \"pts.Waist\", \"pts.Right Knee\"],\n","              \"left_body_knee\" : [\"pts.Nose\", \"pts.Waist\", \"pts.Left Knee\"],\n","              \"right_body_knee\" : [\"pts.Nose\", \"pts.Waist\", \"pts.Right Knee\"],\n","              \"left_knee_hight\" : [\"pts.Left Knee\", \"pts.Left Hip\", \"pts.Back\"],\n","              \"right_knee_hight\" : [\"pts.Right Knee\", \"pts.Right Hip\", \"pts.Back\"],\n","              \"straight_beck\" : [\"pts.Hip\", \"pts.Back\", \"pts.Waist\"],\n","              \"left_leg_direction\" : [\"pts.Left Ankle\", \"pts.Left Knee\", \"pts.Waist\"],\n","              \"right_leg_direction\" : [\"pts.Right Ankle\", \"pts.Right Knee\", \"pts.Waist\"],\n","              \"arm_same_height\" : [\"pts.Left Elbow\", \"pts.Neck\", \"pts.Right Elbow\"],\n","              \"scapula\" : [\"pts.Left Shoulder\", \"pts.Back\", \"pts.Right Shoulder\"],\n","              \"left_knee_cross\" : [\"pts.Left Knee\", \"pts.Hip\", \"pts.Back\"],\n","              \"right_knee_cross\" : [\"pts.Right Knee\", \"pts.Hip\", \"pts.Right Elbow\"],\n","              }\n","angle_list = list(angle_dict.keys())"],"metadata":{"id":"KaqA7OdjftqC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["exercise_condition_dict = {\n","    '푸시업' : ['spine', 'left_elbow', 'right_elbow', 'left_hand_position', 'right_hand_position', 'head'],\n","    '니푸쉬업' : ['spine', 'left_elbow', 'right_elbow', 'left_hand_position', 'right_hand_position', 'head'],\n","    '굿모닝' : ['left_knee','right_knee', 'sight', 'spine'],\n","    'Y-Exercise' : ['arm_same_height', 'left_hand', 'right_hand', 'head'],\n","    '스탠딩 사이드 크런치' : ['spine', 'sight', 'left_knee_elbow','right_knee_elbow', 'left_body_knee','right_body_knee','left_elbow', 'right_hand'],\n","    '스텐딩 니업' : ['sight', 'spine', 'left_knee_hight','right_knee_hight', 'left_knee', 'right_knee'],\n","    '크런치' : ['spine', 'scapula', 'straight_back','left_knee', 'right_knee'],\n","    '바이시클 크런치' : ['spine', 'straight_back', 'left_knee_cross', 'right_knee_cross', 'scapula'],\n","    '플랭크' : ['left_elbow','right_elbow', 'straight_back', 'left_knee', 'right_knee'],\n","    '버피 테스트' : ['spine', 'left_elbow','right_elbow',\"left hand position\", \"right hand position\", 'head'],\n","    '사이드 런지' : ['left_knee', 'right_knee', 'left_leg_direction', 'right_leg_direction', 'spine', 'straight_back'],\n","    '크로스 런지' : ['left_knee', 'right_knee', 'left_leg_direction', 'right_leg_direction','straight_back', 'spine']\n","}"],"metadata":{"id":"82FYRMtNRmy8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 운동 종목 추려내기 + null값, true, false값 바꿔주기, label encoding\n","def data_preprocessing(df_train_3d, df_valid_3d):\n","  # 사용하는 운동종목만 추려내기\n","  df_train_3d = df_train_3d[df_train_3d[\"exercise\"].isin(exercise_list)]\n","  df_valid_3d = df_valid_3d[df_valid_3d[\"exercise\"].isin(exercise_list)]\n","\n","  # null값을 -1로 바꿔줌\n","  # True False값을 학습하기 쉽게 1과 0으로 바꿔줌\n","  df_train_3d = df_train_3d.replace(True, 1)\n","  df_train_3d = df_train_3d.replace(False, 0)\n","  df_valid_3d = df_valid_3d.replace(True, 1)\n","  df_valid_3d = df_valid_3d.replace(False, 0)\n","  df_train_3d = df_train_3d.replace(\"True\", 1)\n","  df_train_3d = df_train_3d.replace(\"False\", 0)\n","  df_valid_3d = df_valid_3d.replace(\"True\", 1)\n","  df_valid_3d = df_valid_3d.replace(\"False\", 0)\n","  df_train_3d = df_train_3d.replace(\"0\", -1)\n","  df_valid_3d = df_valid_3d.replace(\"0\", -1)\n","\n","  # *   condition들의 값은 str임\n","  # *   예시로 \"가슴의 충분한 이동\"이 있음\n","  # *   str을 자연어 학습을 할 때처럼 숫자로 바꿔서 학습해도 되지만, 일단 지금은 각 condition에 해당하는 번호를 할당한 후 LabelEncoder로 값을 바꿔줌.\n","  # *   예시 => {\"가슴의 충분한 이동\" : 1}, {\"견갑골 하강 유지\" : 2} \n","  le = preprocessing.LabelEncoder()\n","  labels = []\n","  labels.extend(exercise_list)\n","  for i in df_train_3d.columns:\n","    if \"condition\" in i:\n","      labels.extend(df_train_3d[df_train_3d[i] != -1][i].unique())\n","      labels.extend(df_valid_3d[df_valid_3d[i]!= -1][i].unique())\n","  le.fit(labels)\n","  for i in le.classes_:\n","    df_train_3d = df_train_3d.replace(i, le.transform([i])[0])\n","    df_valid_3d = df_valid_3d.replace(i, le.transform([i])[0])\n","\n","  return df_train_3d, df_valid_3d, le"],"metadata":{"id":"jRb4C4HYBEn7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train = pd.read_csv(\"../gdrive/MyDrive/EDA/tabular_data/unprocessed_body_3d.csv\")\n","df_valid = pd.read_csv(\"../gdrive/MyDrive/EDA/tabular_data/unprocessed_valid_body_3d.csv\")\n","df_train, df_valid, le = data_preprocessing(df_train, df_valid)"],"metadata":{"id":"krWFVRlVfgi0","executionInfo":{"status":"ok","timestamp":1670306949815,"user_tz":-540,"elapsed":29170,"user":{"displayName":"DK D","userId":"10687755219747411266"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1e2f98a6-7e6e-4280-d572-13c58d571ad7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-7170661fb6dc>:1: DtypeWarning: Columns (75,77,78,79,80,81,82,83,84,85,86,87) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df_train = pd.read_csv(\"../gdrive/MyDrive/EDA/tabular_data/unprocessed_body_3d.csv\")\n"]}]},{"cell_type":"markdown","source":["# SAINT & TabNEt"],"metadata":{"id":"tDFtO0Pj8qzh"}},{"cell_type":"code","source":["from pytorch_widedeep import Trainer\n","from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n","from pytorch_widedeep.models import Wide, TabMlp, WideDeep, SAINT, TabNet\n","from pytorch_widedeep.metrics import Accuracy\n","from keras.utils import to_categorical\n","\n","def train_models(model_name, data_list):\n","  total_acc = 0\n","  for i in range(5):\n","    # Define the 'column set up'\n","    wide_cols = data_list + ['exercise', f'condition{i}']\n","    crossed_cols = [(f'condition{i}', 'exercise')]\n","\n","    cat_embed_cols = [f'condition{i}', 'exercise']\n","    continuous_cols = data_list\n","    target = df_train[f\"value{i}\"].values\n","\n","    # prepare the data\n","    wide_preprocessor = WidePreprocessor(wide_cols=wide_cols, crossed_cols=crossed_cols)\n","    X_wide = wide_preprocessor.fit_transform(df_train[wide_cols])\n","\n","    tab_preprocessor = TabPreprocessor(\n","        cat_embed_cols=cat_embed_cols, continuous_cols=continuous_cols  # type: ignore[arg-type]\n","    )\n","    X_tab = tab_preprocessor.fit_transform(df_train[wide_cols])\n","\n","    # build the model\n","    wide = Wide(input_dim=np.unique(X_wide).shape[0])\n","    if model_name == \"saint\":\n","      tab_mlp = SAINT(\n","          column_idx=tab_preprocessor.column_idx,\n","          cat_embed_input=tab_preprocessor.cat_embed_input,\n","          continuous_cols=continuous_cols,\n","          )\n","    elif model_name == 'tabnet':\n","      tab_mlp = TabNet(\n","          column_idx=tab_preprocessor.column_idx,\n","          cat_embed_input=tab_preprocessor.cat_embed_input,\n","          continuous_cols=continuous_cols,\n","          )\n","    # train and validate\n","    if i<3:\n","      model = WideDeep(deeptabular=tab_mlp)\n","      trainer = Trainer(model, objective=\"binary_focal_loss\", metrics=[Accuracy])\n","    else:\n","      model = WideDeep(deeptabular=tab_mlp, pred_dim = 3)\n","      trainer = Trainer(model, objective=\"multiclass_focal_loss\", metrics=[Accuracy])\n","\n","    trainer.fit(\n","        # X_wide=X_wide,\n","        X_tab=X_tab,\n","        target=target,\n","        n_epochs=4,\n","        batch_size=128,\n","    )\n","    # Save\n","    if data_list == pts_list:\n","      list_name = \"pts\"\n","    elif data_list == angle_list:\n","      list_name = \"angle\"\n","    if not os.path.isdir(f\"../gdrive/MyDrive/{model_name}_{list_name}\"):\n","        os.mkdir(f\"../gdrive/MyDrive/{model_name}_{list_name}\")\n","    torch.save(model.state_dict(), f\"../gdrive/MyDrive/{model_name}_{list_name}/wd_model_{i}.pt\")\n","\n","    # predict on test\n","    X_wide_val = wide_preprocessor.transform(df_valid[wide_cols])\n","    X_tab_val = tab_preprocessor.transform(df_valid[wide_cols])\n","    # X_tab=X_tab_te\n","    preds = trainer.predict(X_tab=X_tab_val)\n","    print(set(preds))\n","    print(preds.shape)\n","    valid_acc = accuracy_score(df_valid[f'value{i}'].values, preds)\n","    print(f\"\\nvalid{i}의 정확도 : {valid_acc}\")\n","    total_acc += valid_acc\n","  print(f\"\\n총 정확도 : {total_acc/5}\")\n","  print(\"=\"*10)"],"metadata":{"id":"rjFwUorQf1XE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # From here in advance, Option 1 or 2 are the same. I assume the user has\n","# # prepared the data and defined the new model components:\n","# # 1. Build the model\n","# model_new = WideDeep(wide=wide, deeptabular=tab_mlp)\n","# model_new.load_state_dict(torch.load(\"./model_weights/wd_model.pt\"))\n","\n","# # 2. Instantiate the trainer\n","# trainer_new = Trainer(model_new, objective=\"binary\")\n","\n","# # 3. Either start the fit or directly predict\n","# preds = trainer_new.predict(X_wide=X_wide_te, X_tab=X_tab_te)\n","# test_acc = accuracy_score(df_valid['value0'].values, preds)\n","# print(test_acc)"],"metadata":{"id":"pHkpQZpEj12Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_models('tabnet', pts_list)\n","train_models('tabnet', angle_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPfrt5BPf12Y","outputId":"bd5ef437-248d-4073-f022-4ebcd6bc42f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/858 [00:00<?, ?it/s]"]}]},{"cell_type":"code","source":["train_models('saint', pts_list)\n","train_models('saint', angle_list)"],"metadata":{"id":"3zQ-vuMRBiwV"},"execution_count":null,"outputs":[]}]}